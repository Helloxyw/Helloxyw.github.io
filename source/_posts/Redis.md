---
title: Redis
date: 2020-04-07 
tags: Redis
---

<h3>1.Redis简介</h3>
简单来说redis就是一个数据库，不过与传统数据库不同的是redis的数据是存在内存中的，所以读写速度非常快，因此redis被广泛应用于缓存方向。另外，redis也经常被用来做分布式锁。redis提供了多种数据类型来支持不同的业务场景。除此之外，redis支持事务、持久化、LUA脚本、LRU驱动事件、多种集群方案

![](https://miro.medium.com/max/1200/1*DPd3_f1ruu3rrkgaFeo2Ug.png)

<!--more-->

<h3>2.为什么要用redis做缓存?</h3>
主要从`高性能`和`高并发`这两点来看待这个问题

**高性能**

假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的访问数据存在缓存中，这样下一次再访问这些数据时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变了之后，同步改变缓存中相应数据即可

**高并发**

直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户一部分的请求会直接到缓存这里，而不用经过数据库



**3.为什么要用redis而不用map/guava做缓存？**

缓存分为本地缓存和分布式缓存。以Java为例，使用自带的map或者guava实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着jvm的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。

使用Redis或memcached之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持redis和memcached服务的高可用，整个程序架构上较为复杂



**4.redis的线程模型**

redis内部使用文件事件处理器`file event handler`，这个文件事件处理器是单线程的，所以redis才叫做单线程的模型。它采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器进行处理

文件事件处理器的结构包含4个部分：

* 多个socket
* IO多路复用程序
* 文件事件分派器
* 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个socket可能会并发产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，会将socket产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理

**5.redis和memcached的区别**

* **redis支持更丰富的数据类型（支持更复杂的应用场景）：**Redis不仅仅支持简单的K/V类型的数据，同时还提供list、set、zest、hash等数据结构的存储。memcached支持简单的数据类型: String
* redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用；而memcached把数据全部存在内存中
* 集群模式：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是Redis目前是原生支持cluster模式的
* Memcached是多线程，非阻塞IO复用的网络模型；redis使用单线程的多路IO复用模型

![image-20200101133849862](/Users/ricardo/Library/Application Support/typora-user-images/image-20200101133849862.png)

**6.redis常用数据结构以及使用场景分析**

**6.1 String**

>常用命令：set、get、decr、incr、mget等

String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。常规key-value缓存应用；常规计数：微博数、粉丝数等

**6.2 Hash**

> 常用命令：hget、hset、hgetall等

hash是一个String类型的field和value的映射表，hash特别适合存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。比如我们可以hash数据结构来存储用户信息、商品信息等。比如下面使用hash类型存放一个个人信息：

```json
key=JavaUser293847
value={
  "id":1,
  "name":"Ricardo",
  "age":24,
  "location":"china"
}
```

**6.3 List**

> 常用命令：lpush、rpush、loop、rpop、lrange等

​        list就是链表，Redis list的应用场景非常多，也是redis最重要的数据结构之一，比如微博的关注列表、粉丝列表、消息列表等功能可以用Redis的list结构来实现。

​       Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销

​	   另外可以通过lrange命令，就是从某个元素开始读取多少个元素，可以基于list实现分页查询，这个很棒的功能，基于Redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高

**6.4 Set **

> 常用命令：sadd、spoop、smembers、sunion等

set对外提供的功能和list类似是一个列表的功能，特殊之处在于set是可以自动排重的。

​		当你需要存储一个列表数据，又不希望出现重复数据使，set可以是一个很好的选择并且set提供了判断某一个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于set轻易实现交集、并集、差集等操作。

​		比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有的粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程，具体命令如下：

```redis
sinterstore key1 key2 key3
```

**6.5 Sorted set**

> 常用命令：zadd、zrange、zrem、zcard等

和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排序。

举例：在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用Redis中的Sorted Set结构进行存储。



**7. Redis过期策略**	

​		Redis中有个设置时间过期的功能，即对存储在redis数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的token或者一些登录信息，尤其短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。

​		我们set key的时候，都可以给一个expire time,就是过期时间，通过过期时间我们可以指定这个key可以存活的时间。如果假设你设置了一批key只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？

过期策略通常有以下三种：

* 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据。从而影响缓存的响应时间和吞吐量。
* 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除，没过期则返回该key对应的value值。该策略可以最大化地节省CPU资源，却对内存很不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

* 定期过期：每隔一定时间（默认100ms)，会扫描一定数量的数据库的expires字典中一定数量的key,并清除其中已经过期的key。该策略是前两者的一个折中方案，通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下是的CPU和内存资源达到最优的平衡效果

  （expires字典会保存所有设置了过期时间的key的过期时间数据，其中key是指向键空间中的某个键的指针，value是改建的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键）

Redis同时采用了**定期删除 + 惰性删除**两种策略。



**8.Redis内存淘汰策略**

但是仅仅通过设置过期时间还是有问题的。如果定期删除漏了很多过期key，然后你也没有及时去查，也就没有走惰性删除，此时会怎样？如果大量过期的key堆积在内存中，导致redis内存块耗尽了。怎么解决这个问题呢？通过**Redis内存淘汰机制**，redis提供了6种数据淘汰策略：

* volatile-lru : 从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
* Volatile-ttl ：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
* volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
* Allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）
* allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
* no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。

4.0版本以后增加了以下两种：

* Volatile-lfu：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰
* Allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key



**9. 缓存雪崩**

如果缓存数据**设置的过期时间是相同的**,导致缓存在某一时刻同时失效，或者缓存服务器宕机导致缓存全面失效，请求全部转发到了DB层面，DB由于瞬间压力增大而导致崩溃，导致整个服务直接瘫痪。这就是缓存雪崩，缓存雪崩导致的雪崩效应对底层系统的冲击是非常大的。

**针对缓存数据设置相同的过期时间，导致某段时间缓存失效，请求全部走数据库**这种情况，非常好解决：

**解决办法（也适用于热点数据集中失效问题）：**

* 第一种：采用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求走到数据库

* 第二种：在缓存的时候给过期时间加上一个**随机值**，这样就会大幅度的**减少缓存在同一时间过期**

**针对“redis"挂掉了，请求全部走数据库这种情况，**我们有以下几种思路：

* 事发前：实现redis的**高可用**（主从架构+Sentinel 或者Redis Cluster），尽量避免Redis挂掉这种情况发生
* 事发中：万一Redis真的挂了，我们可以设置本地缓存（encache) + hystrix限流&降级，避免DB崩掉
* 事发后：redis持久化，重启后自动从磁盘上加载数据，**快速回复缓存数据**



**10.缓存穿透**

缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果**从数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义。

解决方案：

* 第一种：由于每次请求的参数都是不合法的（每次都请求不存在的参数），于是我们可以使用布隆过滤器（BloomFilter)，将所有可能存在的数据哈希到一个足够大的bitMap中，一个一定不存在的数据会被这个bitmap拦截，从而避免对底层存储系统的查询压力。
* 第二种：当我们从数据库找不到的时候，我们也将这个空对象设置到缓存里去边去。下次再请求的时候，就可以从缓存里边获取了。这种情况我们一般会将空对象设置一个**较短的过期时间**

**11.缓存击穿**

在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去，造成某一时刻数据库请求量过大，压力剧增。这种现象我们称为**缓存击穿**。

解决方案：上面的现象是多个线程同时去查询数据库这条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它。其他线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。

**12. 缓存与数据库双写一致**

**读操作**

​		一般我们对于读操作的时候，有这么一个固定套路：

* 如果我们的数据在缓存里边有，那么就直接取缓存里的
* 如果缓存里没有我们想要的数据，我们会先去查询数据库，然后将数据库查出来的数据写到缓存在中
* 最后将数据返回给请求

**什么是缓存与数据库双写不一致问题？**

​		如果仅仅查询的话，缓存的数据和数据库的数据时没问题的。但是我们要**更新**的时候呢，各种情况很可能**造成数据库和缓存的数据不一致**。

​		这里的不一致指的是：**数据库的数据和缓存的数据不一致**

![image-20200101183328576](/Users/ricardo/Library/Application Support/typora-user-images/image-20200101183328576.png)

**更新操作**

一般来说，执行更新操作，我们会有两种选择：

* 先操作数据库，再操作缓存
* 先操作缓存，再操作数据库

首先，要明确的是，无论我们选择操作哪个，我们都希望**这两个操作要么同时成功，要么同时失败。**所以这会演变成**分布式事务**的问题。所以**如果原子性被破坏了**，可能会有以下的情况：

* 操作数据库失败了，操作缓存失败了
* 操作缓存成功了，操作数据库失败了

> 如果第一步已经失败了，我们直接返回Exception出去就好了，第二步根本不会执行

下面具体分析下：

**操作缓存**

操作缓存也有两种方案：

* 更新缓存
* 删除缓存

一般我们都是采取**删除缓存**方案，原因如下：

* 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就**更容易**导致数据库与缓存数据不一致问题（删除缓存**直接和简单**很多）
* 如果每次更新了数据库，都要更新缓存（这里指的是频繁更新的场景，这会耗费一定的性能），倒不如直接删除掉。等再次读取时，缓存里没有，那我到数据库里找，在数据库找到再写到缓存里边（体现懒加载）

基于这两点，对于缓存在更新时而言，都是建议执行**删除操作**！



**（1）先更新数据库，再删除缓存**

正常情况是这样的：

* 先操作数据库，成功；
* 再删除缓存，成功；

如果原子性被破坏了：

* 第一步成功（操作数据库），第二步失败（删除缓存），这会导致**数据库里的是新数据，而缓存里的是旧数据**
* 如果第一步（操作数据库）就失败了，我们直接返回错误（Exception），不会出现数据不一致问题

如果在高并发的场景下，出现数据库与缓存数据不一致的**概率特别低，**也不是没有：

* 缓存**刚好**失效
* 线程A查询数据库，得到一个旧值
* 线程B将新值写入数据库
* 线程B删除缓存
* 线程A将查到的旧值写入缓存

> 因为这个条件要发生在读数据库时缓存失效，并且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，**而读操作必须在写操作前进入数据库操作，而又要晚于写操作更新缓存，**所以这些条件都具备的概率基本不大

对于这种策略，其实是一种设计模式：Cache Aside Pattern

![image-20200101185309530](/Users/ricardo/Library/Application Support/typora-user-images/image-20200101185309530.png)

删除缓存失败的解决思路：

* 将需要删除的key发送到消息队列中
* 自己消费消息，获得需要删除的key
* 不断重试删除操作，直到成功

**（2）先删除缓存，再更新数据库**

正常情况是这样：

* 先删除缓存，成功；
* 再更新数据库，成功；

如果原子性被破坏了：

* 第一步成功（删除缓存），第二步失败（更新数据库），数据库和缓存的数据还是一致的
* 如果第一步（删除缓存）就失败了，我们可以直接返回错误（Exception)，数据库和缓存的数据还是一致的

看起来是很美好，但是我们在并发场景下分析一下，就知道还是有问题的了：

* 线程A删除了缓存
* 线程B查询，发现缓存已经不存在
* 线程B去数据库查询到旧值
* 线程B将旧值写入缓存
* 线程A将新值写入数据库

所以也会导致数据库和缓存不一致问题

**并发下解决数据库和缓存不一致的思路：**

* 将删除缓存、修改数据库、读取缓存等操作积压到队列里边，实现串行化

![image-20200101190113727](/Users/ricardo/Library/Application Support/typora-user-images/image-20200101190113727.png)



**对比两种策略：**

* 先更新数据库，再删除缓存（Cache Aside Pattern模式）
  * 在高并发下表现优异，在原子性被破坏时表现不如意
* 先删除缓存，再更新数据库
  * 在高并发下表现不如意，在原子性被破坏时表现优异

<h3>13：如何实现redis分布式锁--面试解答</h3>

为了实现分布式锁，需要确保锁同时满足以下四个条件：

* 互斥性： 在任意时刻，只能有一个客户端能持有锁
* 不会发送死锁：即使一个客户端持有锁的期间奔溃而没有主动释放锁，也需要保证后续客户端能够加锁成功
* 加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁释放了。
* 容错性：只要大部分的Redis节点正常运行，客户端就可以进行加锁和解锁操作。

**Redis实现分布式锁的正确姿势**

1. 使用setnx命令保证互斥性
2. 需要设置锁的过期时间，避免死锁
3. setnx和设置过期时间需要保持原子性，避免在setnx成功之后再设置过期时间客户端崩溃导致死锁
4. 加锁的value值为一个唯一标识，可以采用UUID作为唯一标识。加锁成功后需要把唯一标识返回客户端，来给客户端进行解锁操作。

**解锁的正确姿势：**

1. 需要拿加锁成功的唯一标识进行解锁，从而保证加锁和解锁是同一客户端
2. 解锁操作需要比较唯一标识是否相等，相等再执行删除操作。这2个操作可以采用Lua脚本方式实现2个命令的原子性



### 14.Redis持久化

​		很多时候我们需要持久化数据，也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。

​		Redis不同于Memcached的很重一点就是，Redis支持赤计划，而且支持两种不同的持久化操作：

* RDB：snapshotting（快照）
* AOF：append-only file（只追加文件）

**RDB**

Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地，以便重启服务器时候使用

RDB是Redis默认采用的持久化方式，在redis.conf配置文件下默认有以下配置：

```

save 900 1       #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 300 10      #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 60 10000    #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

RDB使用bgsave做镜像全量持久化，因为bgsave会耗费较长时间，不够实时。在停机时候会导致大量丢失数据，所以需要AOF配合使用。在redis实例重启时，会使用bgsave持久化文件，重新构建内存，再使用aof重放近期的操作指令，来实现完整恢复重启之前的状态。

bgsave原理： 

* fork：redis通过创建子进程来进行bgsave操作
* Cow ：copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来

**AOF**

与RDB相比，AOF持久化的实时性更好，因此已成为主流的持久化方案。默认情况下，redis没有开启AOF方式的持久化，可以通过appendonly参数开启：

```
appendonly yes
```

开启AOF持久化后每执行一条会更改Redis中的数据的命令，redis就会将该命令写入硬盘中的AOF文件。在Redis的配置文件中存在三种不同的AOF持久化方式，它们分别是：

```
appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
appendfsync no        #让操作系统决定何时进行同步
```

为了兼顾数据和写入性能，用户可以考虑appendfsync everysec选项，让redis 每秒同步一次AOF文件，redis性能几乎没收到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。

**Redis 4.0持久化机制的优化**

redis 4.0 开始支持RDB和AOF的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble开启）。

如果把混合持久化打开，AOF重写的时候就直接把RDB的内容写到AOF文件开头。这样的好处是可以结合RDB和AOF的优点，快速加载同时避免丢失过多的数据。缺点是，AOF里面的RDB部分是压缩格式，不再是AOF格式，可读性较差。

**AOF重写**

​		AOF重写可以产生一个新的AOF文件（AOF 由于每次都会记录写命令，文件会很大，因此需要进行优化），这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。

​		在执行`BGREWRITEAOF`命令时，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新的AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。

